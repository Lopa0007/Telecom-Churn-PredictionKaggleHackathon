{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":78233,"databundleVersionId":8568133,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import libraries\n#Data Structures\nimport pandas as pd\nimport numpy as np\n\n\n#Sklearn\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\n#from sklearn.manifold import TSNE\nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score\n#from imblearn.metrics import sensitivity_specificity_support\nfrom sklearn import metrics\n\nimport xgboost as xgb\nimport re\n\n#Plotting\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\n%matplotlib inline\n\n#Others\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n# display all columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 200)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#import dataset\ndata = pd.read_csv(\"train.csv\")\nunseen = pd.read_csv(\"test.csv\")\n#view data\ndata.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check the target variable\ndata.churn_probability.value_counts()/len(data)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check shape and columns details of the dataframe\nprint(data.shape)\ndata.info(verbose=True, show_counts=True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"markdown","source":"### Data cleaning","metadata":{}},{"cell_type":"code","source":"#missing values\n#we can see from above result that some columns are mostly empty, which will not help with analysis\n#Identify the these coulmns\n(data.isna().sum()/len(data)).sort_values(ascending=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#the customers who have missing values in below column, did not make any data recharge in june 2014, hence, replacing these missing \n#values with zero\n\ncols=[\"arpu_3g_6\",\"count_rech_2g_6\",\"night_pck_user_6\",\"arpu_2g_6\",\"date_of_last_rech_data_6\",\"total_rech_data_6\",\n\"av_rech_amt_data_6\",\"max_rech_data_6\",\"count_rech_3g_6\",\"fb_user_6\"]          \nimp = SimpleImputer(strategy='constant', fill_value=0)\ndata[cols] = imp.fit_transform(data[cols])\n\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#the customers who have missing values in below column, did not make any data recharge in july 2014, hence, replacing these missing \n#values with zero\ncols=[\"night_pck_user_7\",\"date_of_last_rech_data_7\",\"total_rech_data_7\",\"max_rech_data_7\",\"fb_user_7\",\"count_rech_2g_7\",\n\"count_rech_3g_7\",\"arpu_3g_7\",\"av_rech_amt_data_7\",\"arpu_2g_7\"]\nimp = SimpleImputer(strategy='constant', fill_value=0)\ndata[cols] = imp.fit_transform(data[cols])\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#the customers who have missing values in below column, did not make any data recharge in august 2014, hence, replacing these missing \n#values with zero\ncols=[\"count_rech_2g_8\",\"av_rech_amt_data_8\",\"night_pck_user_8\",\"max_rech_data_8\",\"total_rech_data_8\",\"arpu_2g_8\",\"arpu_3g_8\",\n\"date_of_last_rech_data_8\",\"fb_user_8\",\"count_rech_3g_8\"]\nimp = SimpleImputer(strategy='constant', fill_value=0)\ndata[cols] = imp.fit_transform(data[cols])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#there are customers, who did not make any voice call in August, June and july as per below data (total_og_mou*/total_ic_mou*)\ncols=[i for i in list(data.columns) if re.search('mou.+8',i)]\n(data[data.ic_others_8.isna()][cols].head())\ncols=[i for i in list(data.columns) if re.search('mou.+7',i)]\n(data[data.ic_others_7.isna()][cols].head())\ncols=[i for i in list(data.columns) if re.search('mou.+6',i)]\n(data[data.ic_others_6.isna()][cols].head())\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#for such customers, impute the missing values with zero for cols which has voice call usage\ncols=[i for i in list(data.columns) if re.search(\"(mou_6)|(mou_7)|(mou_8)|(ic_others)|(og_others)\",i)]\nfor i in [\"total_og_mou_6\",\"total_og_mou_7\",\"total_og_mou_8\",\"total_ic_mou_6\",\"total_ic_mou_7\",\"total_ic_mou_8\"]:\n    cols.remove(i)\n\nimp = SimpleImputer(strategy='constant', fill_value=0)\ndata[cols] = imp.fit_transform(data[cols])","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#investigate the remaining cols with missing values\ndata[data.date_of_last_rech_8.isna()]\n#employee made voice calls but august, last recharge date is blank for august, similarly for june and july\n#hence dropping such rows, which has genuine missing values in these dates columns\ndata.dropna(subset=['date_of_last_rech_8', 'date_of_last_rech_7',\"date_of_last_rech_6\"], inplace=True)\ndata.shape\ndata[data.loc_og_t2o_mou.isna()].head(5)\ndata[data.loc_og_t2o_mou.isna()].tail(5)\n#a close look reveals that the rows with missing values in loc_og_t2o_mou, std_og_t2o_mou, loc_ic_t2o_mou, have zeroes on all\n#mou column, hence imputing them with zero\ndata[[\"loc_og_t2o_mou\", \"std_og_t2o_mou\", \"loc_ic_t2o_mou\"]] = imp.fit_transform(data[[\"loc_og_t2o_mou\", \"std_og_t2o_mou\", \"loc_ic_t2o_mou\"]])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check for missing values again\n(data.isna().sum()/len(data)).sort_values(ascending=False).head()\n#all missing values are fixed","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape\ndata.info(verbose=1)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dropping variables which is not helpful in analysis\ndata.head()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#drop id, circle id and date variables, \nd_cols=[i for i in list(data.columns) if re.search('date',i)]\nd_cols.append(\"id\")\nd_cols.append(\"circle_id\")\nchurn=data.drop(d_cols, axis=1)\n\nchurn.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#creating total data recharge amount for each months, dropping redundant original variables\ncols=[i for i in list(data.columns) if re.search('rech',i)]\n\nchurn.total_rech_amt_data_6=churn.av_rech_amt_data_6*churn.total_rech_data_6\nchurn.total_rech_amt_data_7=churn.av_rech_amt_data_7*churn.total_rech_data_7\nchurn.total_rech_amt_data_8=churn.av_rech_amt_data_8*churn.total_rech_data_8\nchurn.drop([\"av_rech_amt_data_6\",\"av_rech_amt_data_7\",\"av_rech_amt_data_8\",\"total_rech_data_6\",\"total_rech_data_7\",\"total_rech_data_8\"],axis=1,inplace=True, errors=\"ignore\")\nchurn.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check the categorical variables\nchurn.select_dtypes(\"object\").columns\n#these cols were initially numerical, became object type due to a side effect of SimpleImputer()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#we are not perfoming any outlier treatment for not, we may try the if lower accuracy score is coming with original data\n#check the data type\n#the fb_user*, night_pck_user* variables are binary category variable, changing them to integer for model building. The arpu* \n#columns should be float, other cols can be float or int\nchurn.fb_user_6=churn.fb_user_6.astype('int64')\nchurn.fb_user_7=churn.fb_user_7.astype('int64')\nchurn.fb_user_8=churn.fb_user_8.astype('int64')\nchurn.night_pck_user_6=churn.night_pck_user_6.astype('int64')\nchurn.night_pck_user_7=churn.night_pck_user_7.astype('int64')\nchurn.night_pck_user_8=churn.night_pck_user_8.astype('int64')\nchurn[['max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8',\n       'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8',\n       'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'arpu_3g_6',\n       'arpu_3g_7', 'arpu_3g_8', 'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8']]=churn[['max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8',\n       'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8',\n       'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'arpu_3g_6',\n       'arpu_3g_7', 'arpu_3g_8', 'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8']].astype('float64')\n\n\n\nchurn.select_dtypes(\"object\").columns\n#all columns in numerical format","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#below columns have zeros in all rows, hence dropping these\nprint(churn.sum(axis=0).sort_values().head(10))\nchurn.drop([\"loc_og_t2o_mou\",\"std_og_t2c_mou_8\",\"std_ic_t2o_mou_6\",\"std_ic_t2o_mou_7\",\"std_ic_t2o_mou_8\",\"std_og_t2c_mou_7\",\n           \"std_og_t2c_mou_6\",\"loc_ic_t2o_mou\",\"std_og_t2o_mou\"],axis=1, inplace=True)","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"churn.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Exploratory data analysis","metadata":{}},{"cell_type":"code","source":"# Check Correlation between target variable churn_probability with the other variable in the dataset\nplt.figure(figsize=(10,50))\nchurn.corr()[\"churn_probability\"].abs().sort_values(ascending=False)\n#we are seeing many weak correlation, hence we will check if non-linear model can work well with this\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check distribution of differenr variables which include \"total\" in their name\nt_cols=[i for i in list(churn.columns) if re.search('total',i)]\nt_cols\nfig=plt.subplots(figsize=(20, 20))\n\nfor i, feature in enumerate(t_cols):\n    plt.subplot(10, 3, i+1)\n    plt.subplots_adjust(hspace = 2.0)\n    sns.distplot(x=churn[feature])\n    plt.title(feature)\n    plt.tight_layout()\n\n#the plots looks like right skewed, we will apply scaling before modelling","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check correlation among independent variable,\nchurn.corr()[(churn.corr()>.8) & (churn.corr()<1.0)].abs().unstack().sort_values(kind=\"quicksort\", ascending=False)\n#several variables has high value correlation, hence we can use PCA here","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check the target variable\nchurn.churn_probability.value_counts()/len(churn)\n#imbalanced dataset","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"churn.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Divide the dataset into train and test dataset\n","metadata":{}},{"cell_type":"code","source":"churn_X=churn.drop(\"churn_probability\",axis=1)\nchurn_X.shape\nchurn_y=churn.churn_probability\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test= train_test_split(churn_X, churn_y, train_size = 0.7, test_size = 0.3, random_state = 100,\\\n                                                   stratify=churn.churn_probability.values)\nX_train.shape\ny_test.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"var_cols=X_train.columns","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Feature Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train= scaler.fit_transform(X_train)\nX_train=pd.DataFrame(X_train,columns=var_cols)\nX_train.head()\nX_test= scaler.transform(X_test)\nX_test=pd.DataFrame(X_test,columns=var_cols)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\nX_train.describe()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### perform PCA","metadata":{}},{"cell_type":"code","source":"pca = PCA(random_state=42)\npca.fit(X_train)\npca.explained_variance_ratio_","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#scree plot\nvar_cumu = np.cumsum(pca.explained_variance_ratio_)\nfig = plt.figure(figsize=[5,5])\nplt.vlines(x=15, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\nplt.hlines(y=0.95, xmax=30, xmin=0, colors=\"g\", linestyles=\"--\")\nplt.plot(var_cumu)\nplt.ylabel(\"Cumulative variance explained\")\nplt.show()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#we can see that less than 80 PCs is explaining around 95% of the total variance of the dataset.\n#Perform PCA with 80 components\npca_final = IncrementalPCA(n_components=80)\ntrain_pca = pca_final.fit_transform(X_train)\ntrain_pca.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#np.corrcoef(train_pca.transpose())\n#the principal components are not correlated\n#Applying the transformation on the test set\ntest_pca = pca_final.transform(X_test)\ntest_pca.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Applying logistic regression (with default arguments) on the data on our Principal components","metadata":{}},{"cell_type":"code","source":"lr_pca = LogisticRegression()\nlr_pca=lr_pca.fit(train_pca, y_train)\n#predict probability on test data set\npred_probs_test = lr_pca.predict_proba(test_pca)\nmetrics.roc_auc_score(y_test, pred_probs_test[:,1])\n#test AUC score is pretty good\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predict probability on train data set\npred_probs_train = lr_pca.predict_proba(train_pca)\nmetrics.roc_auc_score(y_train, pred_probs_train[:,1])\n#the test auc score is slightly less than train score, so the model is not overfitting","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#calculate probability\npred_probs_test","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#confusion matric is built based on default probability cutoff 0.5\nconfusion = metrics.confusion_matrix(y_train, lr_pca.predict(train_pca) )\nconfusion","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#accuracy score on train data\nmetrics.accuracy_score(y_train, lr_pca.predict(train_pca))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.accuracy_score(y_test, lr_pca.predict(test_pca))\n# 92% of accuracy score is achieved on test partition without any hyperparameter tuning","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hyperparameter tuning - PCA and Logistic Regression","metadata":{}},{"cell_type":"code","source":"# specify range of hyperparameters to tune\n\nw=[{0:0.1, 1: 0.9}, {0:0.2, 1: 0.8}, {0:0.15, 1: 0.85}, {0:0.05, 1: 0.95}]\nhyper_params = [{'class_weight':w, 'C': [0.1, 0.5, 1, 2, 3, 4, 5, 10], 'penalty': ['l1', 'l2']}]\n\n#create a 5 fold cross-validation scheme\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"estimator_model=LogisticRegression()\nestimator_model\n\nlr_pca2 = GridSearchCV(estimator = estimator_model, \n                          param_grid = hyper_params, \n                          scoring= 'roc_auc', \n                          cv = folds, \n                          return_train_score=True,\n                          verbose = 1)  \nlr_pca2.fit(train_pca, y_train)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(lr_pca2.cv_results_)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print best hyperparameters\nprint(\"Best AUC: \", lr_pca2.best_score_)\nprint(\"Best hyperparameters: \", lr_pca2.best_params_)\n#similar AUC score received \nlr_pca2_final=lr_pca2.best_estimator_\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#AUC score on test set\nlr_pca2_final.fit(train_pca, y_train)\n\nmetrics.roc_auc_score(y_test, pred_probs_test[:,1])\n#the AUC score is improved very slightly\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#determine cutoff probabality\npred_probs_train = lr_pca2_final.predict_proba(train_pca)\ny_train_pred=pd.DataFrame()\ny_train_pred[\"churn_proba\"]=pred_probs_train[:,1]\ny_train_pred","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred[i]= y_train_pred.churn_proba.map(lambda x: 1 if x > i else 0)\ny_train_pred.head()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train, y_train_pred[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from the above table a cut-off prob of .6 will give highest train accuracy score, one of our business goals \n# is to build an ML model that identifies customers who'll definitely churn with more accuracy as compared to the ones \n#who'll not churn, hence we should one maximizing the true positives and minimizing the false negative, that means, for this\n#goal, our target will be to maximise sensitivity while keeping accuracy as much as high","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi'])\nplt.show()\n","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#as per the above plot, cut off prob is .33 when both accuracy and sensitivity are evaluation metric\n#for kaggle competition as the evaluation metric is accuracy score, here we will take the cut-off as .6\n#lets compute accuracy and sensitivity with both the cut off on test data\n\npred_probs_test = lr_pca2_final.predict_proba(test_pca)[:,1]\ntest_prediction=pd.DataFrame()\ntest_prediction[\"actual\"]=y_test\ntest_prediction[\"proba\"]=pred_probs_test\n#map(lambda x: 1 if x > i else 0)\ntest_prediction[\"predicted_.33\"]=test_prediction.proba.map(lambda x: 1 if x > .33 else 0)\ntest_prediction[\"predicted_.6\"]=test_prediction.proba.map(lambda x: 1 if x > .6 else 0)\ntest_prediction.head(5)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_prediction.head(20)\nprint(\"with cutoff .33, the test accuracy score is\",metrics.accuracy_score(test_prediction.actual,test_prediction[\"predicted_.33\"]))\nprint(\"with cutoff .6, the test accuracy score is\",metrics.accuracy_score(test_prediction.actual,test_prediction[\"predicted_.6\"]))\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm33=confusion_matrix(test_prediction.actual,test_prediction[\"predicted_.33\"])\ncm60=confusion_matrix(test_prediction.actual,test_prediction[\"predicted_.6\"])\nprint(\"with cutoff .33, the test sensitivity is\",cm33[1,1]/(cm33[1,0]+cm33[1,1]))\nprint(\"with cutoff .6, the test sensitivity is\",cm60[1,1]/(cm60[1,0]+cm60[1,1]))\n    ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#for kaggle submission, apply this model on unseen data\nunseen.shape\nunseen.head\n","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#apply scaling\nunseen_test=unseen[var_cols]\n(unseen_test.isna().sum()/len(unseen_test)).sort_values(ascending=False)\n#imputing the missing values with zero using same logic we did on train dataset\n\nunseen_test[var_cols] = imp.fit_transform(unseen_test[var_cols])\n(unseen_test.isna().sum()/len(unseen_test)).sort_values(ascending=False).head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check if the dataset has object type columns\nunseen_test.select_dtypes(\"object\").columns\n#all cols are numeric","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#apply scaling\nunseen_test= scaler.transform(unseen_test)\nunseen_test=pd.DataFrame(unseen_test,columns=var_cols)\n\n#apply pca\nunseen_test_pca = pca_final.transform(unseen_test)\nunseen_test_pca.shape\n\npred_probs_unseen = lr_pca2_final.predict_proba(unseen_test_pca)\npred_probs_unseen","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#output the kaggle submission file based on cutoff prob of .6\n#predict churn probalities and storing the same against id\nsubmission_data=pd.DataFrame()\nsubmission_data[\"id\"]=unseen.id\nsubmission_data[\"proba\"]=pred_probs_unseen[:,1]\nsubmission_data[\"churn_probability\"]=submission_data[\"proba\"].map(lambda x: 1 if x > .6 else 0)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_data=submission_data.drop(\"proba\", axis=1)\nsubmission_data","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_data.churn_probability.value_counts()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_data.to_csv('submission_pca_lr.csv',index=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### RandomForest","metadata":{}},{"cell_type":"code","source":"#We got a fair accuracy score using logistic regression, let proceed with Randon Forest for imbalanced data set, so that \n#we can get important features and we will also compare the accuracy with previous model\n#scaling is not required for tree based model\n\nX_train, X_test, y_train, y_test= train_test_split(churn_X, churn_y, train_size = 0.7, test_size = 0.3, random_state = 100,\\\n                                                   stratify=churn.churn_probability.values)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"forest = RandomForestClassifier(random_state=42, n_jobs=-1, criterion='gini', oob_score=True, class_weight={0:0.2, 1: 0.8})\n#using same weight as logistic regression model, to reduce number of fits\nparams = {\n             'n_estimators': [200,300],\n             \"min_samples_leaf\": [30,40,50]\n}\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#performing CV search\nrf = GridSearchCV(estimator=forest,\n                  param_grid=params,\n                  cv = folds,\n                  n_jobs=-1, verbose=1, scoring=\"roc_auc\")\n\nrf.fit(X_train,y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#print(\"oob score\",rf.oob_score_)\nprint(\"best roc_auc\",rf.best_score_)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#select the model which gives best score\nrf_best = rf.best_estimator_\nrf_best","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check AUC score on training dataset\nmetrics.roc_auc_score(y_train, rf_best.predict_proba(X_train)[:,1])\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check AUC score on test dataset\nmetrics.roc_auc_score(y_test, rf_best.predict_proba(X_test)[:,1])","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#both test and train AUC has been improved than logistic regression\n#lets find out the cut-off for highest accuracy and higher sensitivity\n# Let's create columns with different probability cutoffs \ny_train_rf_pred=pd.DataFrame()\ny_train_rf_pred[\"churn_proba\"]=rf_best.predict_proba(X_train)[:,1]\nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_train_rf_pred[i]= y_train_rf_pred[\"churn_proba\"].map(lambda x: 1 if x > i else 0)\ny_train_rf_pred.head()\n","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_rf_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train, y_train_rf_pred[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_rf_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_rf_df)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_rf_df.plot.line(x='prob', y=['accuracy','sensi'])\nplt.show()\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#based on above graph, for highest accuracy, we are taking the cut off .6 \n#for higher sentivity with as high as possible accuracy,  we can take cutoff probability of .25\ntest_rf_prediction=pd.DataFrame()\ntest_rf_prediction[\"actual\"]=y_test\ntest_rf_prediction[\"proba\"]=rf_best.predict_proba(X_test)[:,1]\ntest_rf_prediction[\"predicted_.25\"]=test_rf_prediction[\"proba\"].map(lambda x: 1 if x>.25 else 0)\ntest_rf_prediction[\"predicted_.6\"]=test_rf_prediction[\"proba\"].map(lambda x: 1 if x>.6 else 0)","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_rf_prediction.head()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check test accuracy with .6 of cutoff probobility\nprint(\"Using random forest the test accuracy is\",metrics.accuracy_score(test_rf_prediction[\"actual\"],test_rf_prediction[\"predicted_.6\"]))\nconfusion=metrics.confusion_matrix(test_rf_prediction[\"actual\"],test_rf_prediction[\"predicted_.6\"])\nconfusion\n#we got more test accuracy than logistic regression model","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check sensitivity with .25 of cutoff probability\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\nconfusion=metrics.confusion_matrix(test_rf_prediction[\"actual\"],test_rf_prediction[\"predicted_.25\"])\nsensi_rf_test=confusion[1,1]/(confusion[1,0]+confusion[1,1])\nprint(\"Using random forest the sensitivity on test set is\",sensi_rf_test)\n#we got more sensitivity on test data than logistic regression \nconfusion","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#as we got higher accuracy with RandonForest, lets use the same model on unseen data for kaggle submissin\nunseen.head()\nunseen_rf_test=unseen[var_cols]\nunseen_rf_test.shape\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check missing values\n(unseen_rf_test.isna().sum()/len(unseen_rf_test)).sort_values(ascending=False)\n#imputing the missing values with zero using same logic we did on train dataset\nunseen_rf_test[var_cols] = imp.fit_transform(unseen_rf_test[var_cols])\n(unseen_rf_test.isna().sum()/len(unseen_rf_test)).sort_values(ascending=False).head()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predict churn probalities and storing the same against id\n#output the kaggle submission file based on cutoff prob of .6\npred_probs_rf_unseen = rf_best.predict_proba(unseen_rf_test)\n\nsubmission_rf_data=pd.DataFrame()\nsubmission_rf_data[\"id\"]=unseen.id\nsubmission_rf_data[\"proba\"]=pred_probs_rf_unseen[:,1]\nsubmission_rf_data[\"churn_probability\"]=submission_rf_data[\"proba\"].map(lambda x: 1 if x > .6 else 0)\nsubmission_rf_data.head()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#preparing the file for submission\nsubmission_rf_data=submission_rf_data.drop(\"proba\", axis=1, errors=\"ignore\")\nsubmission_rf_data.head()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_rf_data.churn_probability.value_counts()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_rf_data.to_csv('submission_rf.csv',index=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"#as another ensemble technique XGBoost is preferred for large dataset and high precision accuracy, lets try to predict churn using same\nX_train, X_test, y_train, y_test= train_test_split(churn_X, churn_y, train_size = 0.7, test_size = 0.3, random_state = 100,\\\n                                                   stratify=churn.churn_probability.values)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_cl = xgb.XGBClassifier(n_jobs = -1,objective = 'binary:logistic',random_state=42, class_weight={0:0.2, 1: 0.8})\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A parameter grid for XGBoost\nparams = {\n        'n_estimators' : [200], # no of trees \n        'learning_rate' : [0.05],  # eta\n        'min_child_weight': [1, 5, 7],\n        'gamma': [0.1],\n        'subsample': [0.8],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        \n        }\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n\nparam_comb = 800\n\nsgb = RandomizedSearchCV(xgb_cl, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=-1, cv=folds, verbose=3, random_state=42)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sgb.fit(X_train,y_train)","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"The best ROC_AUC is \",sgb.best_score_)\nxgb_best=sgb.best_estimator_\nxgb_best","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check AUC score on train dataset\nmetrics.roc_auc_score(y_train, xgb_best.predict_proba(X_train)[:,1])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check AUC score on test dataset\nmetrics.roc_auc_score(y_test, xgb_best.predict_proba(X_test)[:,1])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#both test and train AUC has been improved than Random Forest\n#lets find out the cut-off for highest accuracy and higher sensitivity\n# Let's create columns with different probability cutoffs \ny_train_xgb_pred=pd.DataFrame()\ny_train_xgb_pred[\"churn_proba\"]=xgb_best.predict_proba(X_train)[:,1]\nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_train_xgb_pred[i]= y_train_xgb_pred[\"churn_proba\"].map(lambda x: 1 if x > i else 0)\ny_train_xgb_pred.head()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_xgb_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train, y_train_xgb_pred[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_xgb_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_xgb_df)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_xgb_df.plot.line(x='prob', y=['accuracy','sensi'])\nplt.show()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#based on above graph, for highest accuracy, we are taking the cut off .5\n#for higher sentivity with as high as possible accuracy,  we can take cutoff probabilities of .12\ntest_xgb_prediction=pd.DataFrame()\ntest_xgb_prediction[\"actual\"]=y_test\ntest_xgb_prediction[\"proba\"]=xgb_best.predict_proba(X_test)[:,1]\ntest_xgb_prediction[\"predicted_.12\"]=test_xgb_prediction[\"proba\"].map(lambda x: 1 if x>.12 else 0)\ntest_xgb_prediction[\"predicted_.5\"]=test_xgb_prediction[\"proba\"].map(lambda x: 1 if x>.5 else 0)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_xgb_prediction.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check test accuracy with .5 of cutoff probobility\nprint(\"Using xgboost the test accuracy is\",metrics.accuracy_score(test_xgb_prediction[\"actual\"],test_xgb_prediction[\"predicted_.5\"]))\nconfusion=metrics.confusion_matrix(test_xgb_prediction[\"actual\"],test_xgb_prediction[\"predicted_.5\"])\nconfusion\n#we got more test accuracy than logistic regression model","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check sensitivity with .12 of cutoff probability\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\nconfusion=metrics.confusion_matrix(test_xgb_prediction[\"actual\"],test_xgb_prediction[\"predicted_.12\"])\nsensi_xgb_test=confusion[1,1]/(confusion[1,0]+confusion[1,1])\nprint(\"Using XGBoost the sensitivity on test set is\",sensi_xgb_test)\n#we got more sensitivity on test data than logistic regression \nconfusion","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#XGBoost is peforming like random forest with very minimul improvement over accuracy and sentivity","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#as we got higher accuracy with RandonForest, lets use the same model on unseen data for kaggle submissin\nunseen.head()\nunseen_xgb_test=unseen[var_cols]\nunseen_xgb_test.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":" \n#imputing the missing values with zero using same logic we did on train dataset\nunseen_xgb_test[var_cols] = imp.fit_transform(unseen_xgb_test[var_cols])\n(unseen_xgb_test.isna().sum()/len(unseen_xgb_test)).sort_values(ascending=False).head()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predict churn probalities and storing the same against id\n#output the kaggle submission file based on cutoff prob of .5\npred_probs_xgb_unseen = xgb_best.predict_proba(unseen_xgb_test)\n\nsubmission_xgb_data=pd.DataFrame()\nsubmission_xgb_data[\"id\"]=unseen.id\nsubmission_xgb_data[\"proba\"]=pred_probs_xgb_unseen[:,1]\nsubmission_xgb_data[\"churn_probability\"]=submission_xgb_data[\"proba\"].map(lambda x: 1 if x > .5 else 0)\nsubmission_xgb_data.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#preparing the file for submission\nsubmission_xgb_data=submission_xgb_data.drop(\"proba\", axis=1, errors=\"ignore\")\nsubmission_xgb_data.head()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_xgb_data.churn_probability.value_counts()","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_xgb_data.to_csv('submission_xgb.csv',index=False)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Kaggle Submission","metadata":{}},{"cell_type":"code","source":"#Since, XGBoost is giving highest accuracy with a cut-off probability of .5, we are using the predicted output of the same\n#for final kaggle submission.","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_xgb_data.to_csv('Submission.csv',index=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Importance","metadata":{}},{"cell_type":"code","source":"#as both RandomForest and XGBoost are on the par in terms of both accuracy and sensitivity, either of them can be used for \n#feature importance. We are using RandomForest for the same.\nrf_best.feature_importances_\nimp_df = pd.DataFrame({\n    \"Varname\": var_cols,\n    \"Importance_pct\": rf_best.feature_importances_*100\n})\nprint(imp_df.shape)\nimp_df.sort_values(by=\"Importance_pct\", ascending=False)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#the above list shows importance of predictor variables in a descending order but it doesn't give the sign/direction\n#of the same.Hence, taking top 30 variables with highest importance and building a logistic regression on top of these.","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imp=imp_df.sort_values(by=\"Importance_pct\", ascending=False)\nlog_cols=imp.Varname[0:30]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test= train_test_split(churn_X, churn_y, train_size = 0.7, test_size = 0.3, random_state = 100,\\\n                                                   stratify=churn.churn_probability.values)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_log=X_train[log_cols]\nX_test_log=X_test[log_cols]\n\nX_train_log.shape, X_test_log.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#normalizing the variables as we want to retain original data distribution for feature interpretation\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler_log = MinMaxScaler()\nX_train_log= scaler_log.fit_transform(X_train_log)\nX_train_log=pd.DataFrame(X_train_log,columns=log_cols)\n\n\nX_test_log= scaler_log.transform(X_test_log)\nX_test_log=pd.DataFrame(X_test_log,columns=log_cols)\nX_train_log.describe()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_log.describe()\n","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_log.shape, X_test_log.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#build logistic regression using gridsearch\n# specify range of hyperparameters to tune\n\nw=[{0:0.2, 1: 0.8}]\nhyper_params = [{'class_weight':w, \n                 'C': [0.1, 0.5, 1, 2, 3, 4, 5, 10], \n                 'penalty': ['l1', 'l2']}]\n\n#create a 5 fold cross-validation scheme\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logistic=LogisticRegression()\n\n\nlr_feature = GridSearchCV(estimator = logistic, \n                          param_grid = hyper_params, \n                          scoring= 'roc_auc', \n                          cv = folds, \n                          return_train_score=True,\n                          verbose = 1)  \nlr_feature.fit(X_train_log, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#best AUC score\nlr_feature.best_score_","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr_feat_best=lr_feature.best_estimator_\nlr_feature.best_params_","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"the test AUC score is\",metrics.roc_auc_score(y_test,lr_feat_best.predict_proba(X_test_log)[:,1]))\nprint(\"the train AUC score is\",metrics.roc_auc_score(y_train,lr_feat_best.predict_proba(X_train_log)[:,1]))\n#overfitting is avoided","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#extract coefficients for feature importance\nlr_feat_best.coef_","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_coeff=pd.DataFrame()\nfeature_coeff[\"feature\"]=X_train_log.columns\nfeature_coeff[\"coefficients\"]=lr_feat_best.coef_.reshape((-1,1))\nfeature_coeff","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#the features which are positively impacting churn\nfeature_coeff[feature_coeff.coefficients>0]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Recommendations","metadata":{}},{"cell_type":"markdown","source":"1.Customers who are making calls while in roaming tend to leave more. The roaming packages/rates should be \nrevisited base on customer feedback.\n\n2.Instead of data usage, the voice call usage are greatly reducing churn tendency. This is an indicator of good network\nquality. However, it is surprising to not to see much of the data related attributes which are impacting the churn. Since, we \nobserved that highest data recharge amount is reducing churn tendency among customers, more attractive data offers should\nbe proposed in the market considering the current technical advancement of electronics devices.\n\n3.The STD voice call usage is not reducing the churn like local calls, the company should focus on STD rates to improve \nSTD usage.\n\n4.Apart from these, the company should gather the customer queries and complaints information and work on their business strategies accordingly to reduce the churn rate.\n","metadata":{}}]}